{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ed137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tworzenie wykresów z danych wyliczonych w pySpark za pomocą pandas+matplotlib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14515b93",
   "metadata": {},
   "source": [
    "### Przełączamy pySparka na bazę danych uprzednio utworzoną w Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1f030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "moja_nazwa_bazy_danych = \"wpisz_tutaj_nazwe_bazy_danych_z_hive\"\n",
    "spark.sql(f\"use {moja_nazwa_bazy_danych}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734d22e8",
   "metadata": {},
   "source": [
    "### Najprostsza metoda wizualizacji danych jest bezpośrednio wbudowana w Jupytera - dane pobieramy za pomocą SQLa w aplikacji Sparkowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b679f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select \n",
    "    year as tags_year,\n",
    "    sum(tags_counter) as tags_sum\n",
    "from \n",
    "    tags_by_year \n",
    "group by tags_year\n",
    "order by tags_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1f2e15",
   "metadata": {},
   "source": [
    "### Przygotowujemy zbiór z danymi, które będziemy chcieli wizualizować - metoda z matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a5c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_year_sum = spark.sql(\"\"\"\n",
    "select \n",
    "    year as tags_year,\n",
    "    sum(tags_counter) as tags_sum\n",
    "from \n",
    "    tags_by_year \n",
    "group by tags_year\n",
    "order by tags_year\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13a2782",
   "metadata": {},
   "source": [
    "### Kopiujemy nasz DataFrame z aplikacji Sparkowej do pamięci lokalnego procesu Pythonowego\n",
    "#### Uwaga! Duża ilość danych może spowodować wyłączenie się procesu ze względu na limity pamięci\n",
    "#### Do rysowania wykresów maksymalnie obcinamy zakres danych\n",
    "Co dokładnie się dzieje w tym momencie można sprawdzić w dokumentacji sparkmagic: https://github.com/jupyter-incubator/sparkmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3d2fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sprawdzamy jakiego typu jest struktura tags_year_sum\n",
    "type(tags_year_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c42ac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -o local_tags_year_sum\n",
    "local_tags_year_sum = tags_year_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5250fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sprawdzmy jakiego typu typu jest struktura local_tags_year_sum\n",
    "type(local_tags_year_sum)\n",
    "# nastąpiła konwersja do pandasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44377703",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "local_tags_year_sum.plot.bar(x='tags_year',y='tags_sum')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
